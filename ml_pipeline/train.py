import pandas as pd
import polars as pl
import numpy as np
import lightgbm as lgb
import joblib
import os
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# 0. root 경로 선언
from pathlib import Path

ROOT_DIR = Path(__file__).resolve().parents[1]

DATA_DIR = ROOT_DIR / "data" / "raw" #전처리 전 경로
MODELS_DIR = ROOT_DIR / "models" # 모델 저장 경로
SAVE_DIR =ROOT_DIR / "data" / "preprocessed" # 전처리 된 데이터 저장 경로

# 1. 데이터 로드
print("Step 1. 데이터를 불러오는 중입니다...")
train = pl.read_csv(DATA_DIR / "train_v2.csv").to_pandas()
members = pl.read_csv(DATA_DIR / "members_v3.csv").to_pandas()
transactions = pl.read_csv(DATA_DIR / "transactions_v2.csv").to_pandas()
user_logs = pl.read_csv(DATA_DIR / "user_logs_v2.csv", n_rows=5_000_000).to_pandas()

# 2. 데이터 병합 및 변수 생성
print("Step 2. 데이터 병합 및 변수 생성 중...")
transactions['transaction_date'] = pd.to_datetime(transactions['transaction_date'], format='%Y%m%d')
transactions['membership_expire_date'] = pd.to_datetime(transactions['membership_expire_date'], format='%Y%m%d')
transactions['membership_duration'] = (transactions['membership_expire_date'] - transactions['transaction_date']).dt.days

txn_agg = transactions.groupby('msno').agg(
    txn_cnt=('msno', 'count'),
    total_paid=('actual_amount_paid', 'sum'),
    avg_plan_days=('payment_plan_days', 'mean'),
    auto_renew_rate=('is_auto_renew', 'mean'),
    cancel_rate=('is_cancel', 'mean')
).reset_index()

log_agg = user_logs.groupby('msno').agg(
    total_secs_mean=('total_secs', 'mean'),
    num_unq_mean=('num_unq', 'mean')
).reset_index()

df = pd.merge(train, txn_agg, on='msno', how='left')
df = pd.merge(df, log_agg, on='msno', how='left')
df = pd.merge(df, members, on='msno', how='left')
df = df.fillna(0) # 결측치 처리

# 3. 학습 준비
print("Step 3. 학습 데이터 준비 중...")
drop_cols = ['msno', 'is_churn', 'registration_init_time', 'gender', 'membership_expire_date']
X = df.drop(columns=[c for c in drop_cols if c in df.columns])
y = df['is_churn']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 4. 5종 모델 학습 및 저장
print("Step 4. 5종 모델 학습 및 저장 중...")
models = {
    'xgb': XGBClassifier(n_estimators=100, random_state=42),
    'lgbm': lgb.LGBMClassifier(n_estimators=100, random_state=42, verbosity=-1),
    'rf': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
    'gbm': GradientBoostingClassifier(n_estimators=100, random_state=42),
    'mlp': MLPClassifier(hidden_layer_sizes=(128, 64, 32), random_state=42)
}

# ==============================
# 모델 저장
# ==============================
for name, model in models.items():
    if name == 'mlp':
        model.fit(X_train_scaled, y_train)
    else:
        model.fit(X_train, y_train)

    joblib.dump(model, MODELS_DIR / f"{name}_model.pkl")

joblib.dump(scaler, SAVE_DIR / "scaler.pkl")
joblib.dump(list(X.columns), SAVE_DIR / "feature_names.pkl")
print("✅ 모든 모델 저장 완료!")